{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to torch study without torchtext\n",
    "## 1월 3주차 : Convolutional Sentiment Analysis\n",
    "논문 디테일 구현해보기\n",
    "- load pretrained word embedding (v)\n",
    "- unk token initialize with uniform distribution (v)\n",
    "- ada-delta optimizer (v)\n",
    "- L2 weight norm (v)\n",
    "- L2 weight constraint (v)\n",
    "- multi-channel model (v)\n",
    "- K-fold (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available() \n",
    "device = 'cuda: 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/yoonkim/CNN_sentence 레파지토리 clone 한 경로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Windows' in platform.platform():\n",
    "    path = 'C:/Users/long8v'\n",
    "else:\n",
    "    path = '/home/long8v'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용자 Dataset정의\n",
    "- I/O \n",
    "- preprocess\n",
    "- tokenizer\n",
    "- Vocab 객체 만들기<br>\n",
    "   = vocab_len<br>\n",
    "   = stoi<br>\n",
    "   = itos\n",
    "- k-fold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 규민님 코드 \n",
    "# tokenizer가 변경되면 Vocab도 변경되어야하니까 tokenzier 부분은 Dataset에서 하는게 맞지 않을까?\n",
    "# Vocab에서 build vocab하는건 토큰화된 문장들이 들어있는 이중리스트가 되어야 나중에 편할 것 같음!\n",
    "class Vocab:    \n",
    "    def build_vocabs(self, sentence_list):\n",
    "        from collections import defaultdict\n",
    "        self.stoi_dict = defaultdict(lambda: 0) # 원래 <UNK>로 되어있었음\n",
    "        self.stoi_dict['<UNK>'] = 0\n",
    "        self.stoi_dict['<PAD>'] = 1\n",
    "        _index = 2\n",
    "        for sentence in sentence_list:\n",
    "            tokens_list = sentence\n",
    "            for word in tokens_list:\n",
    "                if word in self.stoi_dict:\n",
    "                    pass\n",
    "                else:\n",
    "                    self.stoi_dict[word] = _index\n",
    "                    _index += 1\n",
    "        self.itos_dict = {v:k for k, v in self.stoi_dict.items()}\n",
    "        \n",
    "    def stoi(self, token_list):\n",
    "#         if type(sentence) == str: # sentence 한 개 가 들어온 경우\n",
    "        return [self.stoi_dict[word] for word in token_list]\n",
    "#         elif type(sentence) == list: # sentence 여러 개가 리스트로 들어온 경우\n",
    "#             return [self.stoi(i) for i in sentence]\n",
    "\n",
    "    def itos(self, indices):\n",
    "#         if type(indices[0]) == int : # sentence 한 개가 들어온 경우, 공백으로 join해서 문장으로 만들어줌\n",
    "        return \" \".join([self.itos_dict[index] for index in indices if self.itos_dict[index] != '<PAD>'])\n",
    "#         elif type(indices) == list: # sentence 여러 개가 들어온 경우, 공백으로 join한 문장 리스트를 만들어줌\n",
    "#             return [self.itos(i) for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I/O 하기\n",
    "with open(f'{path}/CNN_sentence/rt-polarity.pos', 'r', encoding = \"ISO-8859-1\") as f:\n",
    "    pos = f.readlines()\n",
    "with open(f'{path}/CNN_sentence/rt-polarity.neg', 'r', encoding = \"ISO-8859-1\") as f:\n",
    "    neg = f.readlines()\n",
    "pos = [(p, 1) for p in pos]\n",
    "neg = [(n, 0) for n in neg]\n",
    "data = pos + neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid = train_test_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# 이거 load하는데 너무 오래걸려서 객체 가져온 다음에 train, valid할 때 재활용하는게 나을듯하다\n",
    "w2v = KeyedVectors.load_word2vec_format(f'{path}/Downloads/GoogleNews-vectors-negative300.bin.gz', \n",
    "                                binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = Vocab()\n",
    "# vocab.build_vocabs(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNDataset: # 굳이 Dataset 상속을 안해줘도 된다고 함\n",
    "    def __init__(self, path, w2v):\n",
    "        data = self.load_data(path)\n",
    "        zipped_data = list(zip(*data))\n",
    "        \n",
    "        # 전처리하는 과정 __getitem__에서 안 한 이유는 vocab 만들때 같은 전처리를 사용해야해서..!!\n",
    "        self.text = zipped_data[0]\n",
    "        self.text = [self.clean_str(sen) for sen in self.text]\n",
    "        self.text = [[word for word in self.tokenizer(sen)] for sen in self.text]\n",
    "        self.label = zipped_data[1]\n",
    "        \n",
    "        # vocab 만들기 -> class 안에 다른 class instance를 정의하는게 보편적인지는 잘 모르겠음\n",
    "        # ...이렇게 하면 문제점이 생기는게, train, valid, test 따로따로 build_vocab을 만들어서 안됨!!! 어떡하지\n",
    "        self.vocab = Vocab()\n",
    "        self.vocab.build_vocabs(self.text)    \n",
    "        self.pretrained_embedding = self.get_pretrained_embeddings()\n",
    "        self.w2v = w2v\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_label = self.label[idx]\n",
    "        sample_text = self.text[idx]\n",
    "        sample_text = self.vocab.stoi(sample_text)\n",
    "        return torch.Tensor(sample_text).long(), sample_label\n",
    "    \n",
    "    def load_data(self, path):\n",
    "        ## I/O 하기\n",
    "        with open(f'{path}/CNN_sentence/rt-polarity.pos', 'r', encoding = \"ISO-8859-1\") as f:\n",
    "            pos = f.readlines()\n",
    "        with open(f'{path}/CNN_sentence/rt-polarity.neg', 'r', encoding = \"ISO-8859-1\") as f:\n",
    "            neg = f.readlines()\n",
    "        pos = [(p, 1) for p in pos]\n",
    "        neg = [(n, 0) for n in neg]\n",
    "        return pos + neg\n",
    "    \n",
    "    def tokenizer(self, sentence):\n",
    "        return sentence.split()\n",
    "    \n",
    "    def get_pretrained_embeddings(self):\n",
    "        pretrained_embedding = []\n",
    "        for word in self.vocab.stoi_dict:\n",
    "            if word in w2v:\n",
    "                pretrained_embedding.append(w2v[word])\n",
    "            else: \n",
    "                pretrained_embedding.append(np.random.uniform(-0.25, 0.25, 300))\n",
    "        return torch.from_numpy(np.array(pretrained_embedding))        \n",
    "    \n",
    "    def clean_str(self, string, TREC=False):\n",
    "        \"\"\"\n",
    "        Tokenization/string cleaning for all datasets except for SST.\n",
    "        Every dataset is lower cased except for TREC\n",
    "        \"\"\"\n",
    "        string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n",
    "        string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
    "        string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "        string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n",
    "        string = re.sub(r\"\\'re\", \" \\'re\", string) \n",
    "        string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "        string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "        string = re.sub(r\",\", \" , \", string) \n",
    "        string = re.sub(r\"!\", \" ! \", string) \n",
    "        string = re.sub(r\"\\(\", \" \\( \", string) \n",
    "        string = re.sub(r\"\\)\", \" \\) \", string) \n",
    "        string = re.sub(r\"\\?\", \" \\? \", string) \n",
    "        string = re.sub(r\"\\s{2,}\", \" \", string)     \n",
    "        return string.strip() if TREC else string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CNNDataset(path, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  3,  4,  5,  6,  7,  2,  8,  9, 10, 11, 12, 13, 14, 15, 10, 16,  6,\n",
      "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])\n",
      "1\n",
      "the rock is destined to be the 21st century 's new conan and that he 's going to make a splash even greater than arnold schwarzenegger , jean claud van damme or steven segal\n"
     ]
    }
   ],
   "source": [
    "for data, label in dataset:\n",
    "    print(data)\n",
    "    print(label)\n",
    "    print(dataset.vocab.itos(np.array(data)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f6ccd641e10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subset(dataset, [1, 2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf_splitted = kf.split(dataset)\n",
    "kf_list_index = list(kf_splitted)\n",
    "kf_folded = [(Subset(dataset, train_idx), Subset(dataset, test_idx)) \n",
    "             for train_idx, test_idx in kf_list_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나중에 패키지화 하면 해봐야지 지금은 복잡해서 못하겠음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이쯤 되니까 torchtext를 그냥 사용하는 것도 나쁘지 않다는 생각이 들었음..<br>\n",
    "min_df가 있으면 이제 또 defaultdict(int)해갖고 해야될텐데..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    return xx_pad, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = random_split(dataset, [int(len(dataset)*0.9), len(dataset) - int(len(dataset)*0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=bs, collate_fn=pad_collate, drop_last=False)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs, collate_fn=pad_collate, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "CNN은 보통 이미지에서 많이 사용된다. 이미지는 보통 가로, 세로로 2 차원이다.(RGB 차원은 추후에 논의). 그에 반해 text는 1차원이다. 하지만 우리는 단어를 word embedding을 통해 차원을 늘린다. 그래서 우리가 단어를 2차원으로 보는 이유다. \n",
    "\n",
    "우리는 [ n x emb_dim ]인 filter를 사용하게 된다. 이것은 n개의 연속적인 단어를 커버하고, 우리의 너비는 emb_dim이 되게된다. 두개의 단어를 한번에 보는 필터는(=bi-grams) [ 2 x emb_dim ] 필터가 될 것이다.\n",
    "필터는 이미지의 아래로 내려가면서 bi-gram을 커버하고 결과가 계산된다. 결과의 output vector는 이미지의 높이 - 필터의 높이 + 1 만큼 되게 된다.\n",
    "\n",
    "이 예시는 하나의 필터가 어떻게 계산하는지를 보여준다. 그러나 우리의 모델은 이러한 필터를 여러개 사용하게 된다. 주요 아이디어는 각각의 필터가 다른 피쳐를 뽑는다는 것이다. 우리의 모델에서는 다른 크기의 필터를 쓸 것이다. 높이 3, 4, 5의 필터를 각각 100개씩 사용할 것이다. 이를 통해 tri-gram, 4-gram, 5-gram을 사용하는 효과를 가졌으면 좋겠다.\n",
    "\n",
    "다음 단계는 pooling을 하는 과정이다. 이것은 각각의 단어 벡터에서 평균을 구한 FastText와 비슷하다. 그러나 우리는 대신 max value를 구할 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6., 8.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2,3,4]).add_(torch.Tensor([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-channel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, pretrained_embedding, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # we experiment with having two 'channels' of word vector\n",
    "        # ... each filter is applied to calculate c_i\n",
    "        # ... and the results are added to cacluate c_i\n",
    "        self.static_embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.nonstatic_embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.static_embedding.from_pretrained(pretrained_embedding.clone().detach())\n",
    "        self.nonstatic_embedding.from_pretrained(pretrained_embedding.clone().detach(), \n",
    "                                                 max_norm=3.0, freeze=False)\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout()\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text = [batch size, sent len]\n",
    "        ## static embedding \n",
    "        embedded = self.nonstatic_embedding(text)\n",
    "        embedded_static = self.static_embedding(text)\n",
    "#         print(f'|embedded_shape| {embedded.shape}')\n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        embedded_static = embedded_static.unsqueeze(1)\n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) + F.relu(conv(embedded_static)).squeeze(3) \n",
    "                  for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved] \n",
    "        cat = torch.cat(pooled, dim = 1)\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)] \n",
    "        output = self.dropout(cat)\n",
    "        output = self.fc(output)\n",
    "        # ouput [batch size, output_dim]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also implement the above model using 1-dimensional convolutional layers, where the embedding dimension is the \"depth\" of the filter and the number of tokens in the sentence is the width.\n",
    "\n",
    "We'll run our tests in this notebook using the 2-dimensional convolutional model, but leave the implementation for the 1-dimensional model below for anyone interested. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of our `CNN` class. \n",
    "\n",
    "We can change `CNN` to `CNN1d` if we want to run the 1-dimensional convolutional model, noting that both models give almost identical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(dataset.vocab.stoi_dict)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 2\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = dataset.vocab.stoi_dict['<PAD>']\n",
    "pretrained_vector = dataset.pretrained_embedding\n",
    "\n",
    "model = CNN(pretrained_vector, INPUT_DIM, EMBEDDING_DIM, N_FILTERS, \n",
    "            FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of parameters in our model we can see it has about the same as the FastText model. \n",
    "\n",
    "Both the `CNN` and the `CNN1d` models have the exact same number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 11,621,102 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load the pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then zero the initial weights of the unknown and padding tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is the same as before. We initialize the optimizer, loss function (criterion) and place the model and criterion on the GPU (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "device = 'cpu'\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "optimizer = optim.Adadelta(model.parameters(), rho=0.95)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the function to calculate accuracy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, max_pool1d torch.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.Tensor([[1,2,3,4],[1,2,3,4]]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, max_pool1d torch.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    #round predictions to the closest integer\n",
    "    argmax = torch.argmax(preds, dim=1)\n",
    "    correct = (argmax == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function for training our model...\n",
    "\n",
    "**Note**: as we are using dropout again, we must remember to use `model.train()` to ensure the dropout is \"turned on\" while training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TORCH.CLAMP`\n",
    "**torch.clamp(input, min, max, *, out=None)** → Tensor\n",
    "Clamp all elements in input into the range [ min, max ] and return a resulting tensor:\n",
    "\\begin{cases} \\text{min} & \\text{if } x_i < \\text{min} \\\\ x_i & \\text{if } \\text{min} \\leq x_i \\leq \\text{max} \\\\ \\text{max} & \\text{if } x_i > \\text{max} \\end{cases}\n",
    "\t\n",
    " \n",
    "If input is of type FloatTensor or DoubleTensor, args min and max must be real numbers, otherwise they should be integers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    max_val = 3\n",
    "    eps = 1e-12\n",
    "    if 'fc.weight' in name:\n",
    "        norm = torch.norm(param, 2, dim=0)\n",
    "        desired = torch.clamp(norm, 0, max_val)\n",
    "        param = param * (desired / (eps + norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(batch[0])\n",
    "\n",
    "        loss = criterion(predictions, torch.Tensor(batch[1]).long())\n",
    "        \n",
    "#         ## l2 weight norm https://stackoverflow.com/questions/42704283/adding-l1-l2-regularization-in-pytorch\n",
    "#         l2_lambda = 0.01\n",
    "#         l2_reg = torch.tensor(0., requires_grad=False)\n",
    "#         for param in model.parameters():\n",
    "#             l2_reg.data.add_(torch.sqrt(torch.norm(param)))\n",
    "#             loss.add_(l2_lambda * l2_reg)\n",
    "\n",
    "        acc = softmax_accuracy(predictions, torch.Tensor(batch[1]).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "                \n",
    "        ## max-norm \n",
    "        for name, param in model.named_parameters():\n",
    "            max_val = 3\n",
    "            eps = 1e-12\n",
    "            if 'fc.weight' in name:\n",
    "                norm = torch.norm(param, 2, dim=0)\n",
    "                desired = torch.clamp(norm, 0, max_val)\n",
    "                param.data *= (desired / (eps + norm))\n",
    "        \n",
    "    \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function for testing our model...\n",
    "\n",
    "**Note**: again, as we are now using dropout, we must remember to use `model.eval()` to ensure the dropout is \"turned off\" while evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            predictions = model(batch[0]).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions, torch.Tensor(batch[1]).long())\n",
    "            \n",
    "            acc = softmax_accuracy(predictions, torch.Tensor(batch[1]).long())\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our function to tell us how long epochs take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train our model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> loss = nn.CrossEntropyLoss()\n",
    ">>> input = torch.randn(3, 5, requires_grad=True)\n",
    ">>> target = torch.empty(3, dtype=torch.long).random_(5)\n",
    ">>> output = loss(input, target)\n",
    ">>> output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]), torch.Size([3]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.054 | Train Acc: 54.49%\n",
      "\t Val. Loss: 0.737 |  Val. Acc: 55.42%\n",
      "Epoch: 02 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.857 | Train Acc: 57.44%\n",
      "\t Val. Loss: 0.658 |  Val. Acc: 63.77%\n",
      "Epoch: 03 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.902 | Train Acc: 61.45%\n",
      "\t Val. Loss: 0.971 |  Val. Acc: 56.57%\n",
      "Epoch: 04 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.818 | Train Acc: 65.97%\n",
      "\t Val. Loss: 0.715 |  Val. Acc: 64.79%\n",
      "Epoch: 05 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.789 | Train Acc: 70.04%\n",
      "\t Val. Loss: 1.375 |  Val. Acc: 55.94%\n",
      "Epoch: 06 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.666 | Train Acc: 75.27%\n",
      "\t Val. Loss: 0.897 |  Val. Acc: 64.04%\n",
      "Epoch: 07 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.531 | Train Acc: 80.65%\n",
      "\t Val. Loss: 0.969 |  Val. Acc: 64.49%\n",
      "Epoch: 08 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.415 | Train Acc: 85.08%\n",
      "\t Val. Loss: 1.096 |  Val. Acc: 62.05%\n",
      "Epoch: 09 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.368 | Train Acc: 87.69%\n",
      "\t Val. Loss: 1.269 |  Val. Acc: 62.86%\n",
      "Epoch: 10 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.312 | Train Acc: 89.88%\n",
      "\t Val. Loss: 1.217 |  Val. Acc: 64.41%\n",
      "Epoch: 11 | Epoch Time: 0m 24s\n",
      "\tTrain Loss: 0.281 | Train Acc: 90.94%\n",
      "\t Val. Loss: 1.360 |  Val. Acc: 63.21%\n",
      "Epoch: 12 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.252 | Train Acc: 92.38%\n",
      "\t Val. Loss: 1.404 |  Val. Acc: 63.78%\n",
      "Epoch: 13 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.209 | Train Acc: 93.28%\n",
      "\t Val. Loss: 1.722 |  Val. Acc: 61.24%\n",
      "Epoch: 14 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.227 | Train Acc: 93.45%\n",
      "\t Val. Loss: 1.659 |  Val. Acc: 65.03%\n",
      "Epoch: 15 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.192 | Train Acc: 94.59%\n",
      "\t Val. Loss: 1.594 |  Val. Acc: 63.23%\n",
      "Epoch: 16 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.193 | Train Acc: 94.64%\n",
      "\t Val. Loss: 1.767 |  Val. Acc: 63.68%\n",
      "Epoch: 17 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.150 | Train Acc: 95.53%\n",
      "\t Val. Loss: 1.919 |  Val. Acc: 64.05%\n",
      "Epoch: 18 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.153 | Train Acc: 95.56%\n",
      "\t Val. Loss: 1.880 |  Val. Acc: 63.96%\n",
      "Epoch: 19 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.146 | Train Acc: 96.02%\n",
      "\t Val. Loss: 1.876 |  Val. Acc: 65.14%\n",
      "Epoch: 20 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.132 | Train Acc: 96.59%\n",
      "\t Val. Loss: 1.905 |  Val. Acc: 64.68%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "best_valid_accuracy = float(0)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_dl, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_dl, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_acc > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_acc\n",
    "        torch.save(model.state_dict(), f'{path}/torch_study/data/tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get test results comparable to the previous 2 models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.876 | Test Acc: 65.14%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'{path}/torch_study/data/tut4-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, valid_dl, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input\n",
    "\n",
    "And again, as a sanity check we can check some input sentences\n",
    "\n",
    "**Note**: As mentioned in the implementation details, the input sentence has to be at least as long as the largest filter height used. We modify our `predict_sentiment` function to also accept a minimum length argument. If the tokenized input sentence is less than `min_len` tokens, we append padding tokens (`<pad>`) to make it `min_len` tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = lambda e: e.split()\n",
    "\n",
    "def predict_sentiment(model, sentence, min_len = 5):\n",
    "    model.eval()\n",
    "    tokenized = [tok for tok in tokenizer(sentence)]\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [dataset.vocab.stoi_dict[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.argmax(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example negative review..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is terrible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example positive review..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "long36v",
   "language": "python",
   "name": "long36v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
