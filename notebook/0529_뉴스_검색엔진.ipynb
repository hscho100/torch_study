{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from konlpy.tag import Komoran\n",
    "from collections import defaultdict\n",
    "from math import log10, log2, sqrt\n",
    "import re\n",
    "import bad_at_io\n",
    "import ngram\n",
    "from string import punctuation\n",
    "from re_DIY import re_DIY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = defaultdict(lambda: defaultdict(int))\n",
    "max_tf = defaultdict(int)\n",
    "df = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "for section in listdir(\"scraping/Daum\"):\n",
    "    for f in bad_at_io.fileid(\"scraping/Daum/\"+section+\"/\"):\n",
    "        content = bad_at_io.txt_open(f)\n",
    "        content = re_DIY(content)\n",
    "        for token in word_tokenize(content):\n",
    "            for _ in ma.pos(token):\n",
    "                if _[1].startswith(\"N\"):\n",
    "                    tf[f][\"/\".join(_)] += 1\n",
    "        for _ in tf[f].keys():\n",
    "            df[_] += 1\n",
    "        max_tf[f] = max(tf[f].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(max_tf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = {key:log2(N/(value+1)) for key, value in df.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubleTF = defaultdict(lambda: defaultdict(int))\n",
    "TFIDF = defaultdict(lambda: defaultdict(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article, values in tf.items():\n",
    "    for term, freq in values.items():\n",
    "        doubleTF[article][term] = tf[article][term] / max_tf[article] \n",
    "        TFIDF[article][term] = 0.5 + (1-0.5) * (doubleTF[article][term] * idf[term])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"돈까스\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_q = defaultdict(int)\n",
    "df_q = defaultdict(int)\n",
    "idf_q = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = re_DIY(query)\n",
    "for token in word_tokenize(query):\n",
    "    for _ in ma.pos(token):\n",
    "        tf_q[\"/\".join(_)] +=1\n",
    "        df_q[\"/\".join(_)] = df[\"/\".join(_)]\n",
    "idf_q = {key:log2(N/(value+1)) for key, value in df_q.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tf_q = max(tf_q.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubleTF_q = defaultdict(int)\n",
    "TFIDF_q = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term, freq in  tf_q.items():\n",
    "    doubleTF_q[term] = tf_q[term] / max_tf_q\n",
    "    TFIDF_q[term] = 0.5 + (1-0.5) * (doubleTF_q[term] * idf_q[term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'돈까스/NA': 4.169925001442312})"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_T = defaultdict(lambda: defaultdict(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article, freq_dict in TFIDF.items():\n",
    "    for term, freq in freq_dict.items():\n",
    "        TFIDF_T[term][article] = TFIDF[article][term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TFIDF.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'돈까스/NA': 4.169925001442312})"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article, freq_dict in TFIDF.items():\n",
    "    for term, freq in freq_dict.items():\n",
    "        LENGTH[article] += freq**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = {key:sqrt(value) for key, value in LENGTH.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "COSINE = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term, freq in TFIDF_q.items():\n",
    "    if term in TFIDF_T.keys():\n",
    "        for article, value in TFIDF_T[term].items():\n",
    "            COSINE[article] += (TFIDF_T[term][article] * TFIDF_q[term]) / LENGTH[article]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show top K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = sorted(COSINE.items(),key=lambda e: e[1], reverse = True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, similarity in search_result:\n",
    "    print(file.split(\"/\")[-1])\n",
    "    print(\"similarity is {0:.3f}%\".format(similarity*100))\n",
    "    print(\" \".join(bad_at_io.txt_open(file).split()[:100]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
